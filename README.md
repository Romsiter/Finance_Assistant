# 🧠 Voice-Based Finance Assistant

An AI-powered assistant that lets users ask financial questions by voice. The system transcribes audio using Whisper, performs intelligent financial data retrieval and analysis using autonomous agents, and replies back with synthesized speech using OpenAI TTS.

---

## 🚀 Features

- 🎙️ Voice input via microphone (Streamlit frontend)
- 📝 Automatic transcription using Whisper
- 🧠 CrewAI agents that retrieve market data, run analysis, and generate a natural language summary
- 🔈 TTS audio response using OpenAI's `tts-1` model
- 🌐 FastAPI backend for handling the pipeline
- 🧩 Modular, agent-based architecture for extensibility

---

## 🧑‍💼 Use Case: Financial Voice Assistant

This assistant is built for retail investors or analysts who want spoken updates on stocks, economic indicators, or news summaries without typing.

---

## 🛠️ CrewAI Agent Roles

| Agent           | Purpose |
|-----------------|---------|
| **Stock Agent** | Retrieves stock price and performance data |
| **Scraper Agent** | Collects financial headlines or news |
| **Retriever Agent** | Finds relevant context using vector databases |
| **Analysis Agent** | Synthesizes all info into coherent insights |
| **Language Agent** | Refines language for clarity and quality |
| **TTS Agent** | Converts the final summary into spoken audio (`.wav` format) |

---

## 🧩 Workflow Overview

1. 🎤 User records a voice query using the Streamlit frontend.
2. 📤 Audio is sent to FastAPI `/process_query` endpoint.
3. 🔊 Whisper transcribes the audio to text.
4. 🧠 CrewAI agents collaborate to understand, retrieve, and synthesize financial data.
5. 📄 The final summary is written to `final_answer.txt`.
6. 🔈 The TTS Agent reads it and creates `tts_xxx.wav`.
7. 📥 The frontend plays the response as audio.

---

## 📦 Installation

### 1. Clone the repo
```bash
git clone https://github.com/Romsiter/Finance_Assistant.git
cd Finance_Assistant
```

### 2. Create and Activate a Virtual Environment
```bash
python -m venv venv
source venv/bin/activate      # On Windows: venv\Scripts\activate
```
###3. Install Dependencies
```bash
pip install -r requirements.txt
```
### 4. Set Your Environment Variables
Create a .env file in the project root:

```env
OPENAI_API_KEY=your_openai_api_key
ALPHAVANTAGE_API_KEY=your_api_key
```
## ▶️ How to Run Locally
### Step 1: Start the FastAPI Backend
```bash
uvicorn main:app --reload
```

### Step 2: Launch the Streamlit Frontend
In a new terminal window (with the virtual environment still activated):

```bash
streamlit run streamlit_app.py
```


## 🎤 Usage Example
1. Open the Streamlit app in your browser.

2. Click "🎤 Record Audio" and speak your query (e.g. "What's the latest news about Apple stock?").

3. Click "🧠 Get Market Brief" to process your audio.

4. The assistant will:

  -Transcribe your speech using Whisper
  
  - Retrieve and analyze financial data using CrewAI agents
  
  -Synthesize a response
  
  -Speak the response back using OpenAI TTS

## 📁 File Structure
```bash
Copy
Edit
├── main.py                  # FastAPI backend with Whisper + Crew
├── streamlit_app.py         # Frontend interface for voice input/output
├── final_answer.txt         # Final summary generated by agents
├── requirements.txt         # Python dependencies
├── .env                     # API keys and secrets

```

## 🧠 Technologies Used
FastAPI – REST backend

Streamlit – UI frontend

OpenAI Whisper – Speech-to-text

OpenAI TTS (tts-1) – Text-to-speech

CrewAI – Agent-based task delegation

LangChain – Vector retrieval and document QA

SoundDevice + SoundFile – For local audio recording

Faiss – Fast vector search engine for embedding lookups


